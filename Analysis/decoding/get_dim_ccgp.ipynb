{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0997f3d-4d3a-4b15-aee2-e32944f042c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.svm, sklearn.discriminant_analysis, sklearn.linear_model\n",
    "import time\n",
    "\n",
    "root = '/usr/local/serenceslab/maggie/shapeDim/'\n",
    "\n",
    "sys.path.append(os.path.join(root, 'Analysis'))\n",
    "from code_utils import file_utils, data_utils\n",
    "from code_utils import decoding_utils\n",
    "from code_utils import stats_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b24bbf-3de3-430e-a47c-96af32542209",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=True; n_threads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ca7f00-91b7-47eb-8ea9-cd9b9bcddf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug = True, n_threads = 8\n",
      "loading S01, main task\n",
      "loading S01, repeat task\n"
     ]
    }
   ],
   "source": [
    "print('debug = %s, n_threads = %d'%(debug, n_threads))\n",
    "\n",
    "subjects = [1]\n",
    "# subjects = np.arange(1,8)\n",
    "n_subjects = len(subjects)\n",
    "n_rois = 11\n",
    "make_time_resolved=False\n",
    "\n",
    "# first load all data for all subjects, all tasks\n",
    "maindat_all = []; repdat_all = []\n",
    "mainlabs_all = []; replabs_all = []\n",
    "\n",
    "for si, ss in enumerate(subjects):\n",
    "\n",
    "    print('loading S%02d, main task'%ss)\n",
    "    main_data, _, main_labels, roi_names = data_utils.load_main_task_data(ss, make_time_resolved)\n",
    "\n",
    "    for ri in range(n_rois):\n",
    "        # subtract mean across voxels each trial\n",
    "        main_data[ri] -= np.tile(np.mean(main_data[ri], axis=1, keepdims=True), [1, main_data[ri].shape[1]])\n",
    "\n",
    "    maindat_all += [main_data]\n",
    "    mainlabs_all += [main_labels]\n",
    "\n",
    "    print('loading S%02d, repeat task'%ss)\n",
    "    rep_data, _, rep_labels, roi_names = data_utils.load_repeat_task_data(ss, make_time_resolved)\n",
    "\n",
    "    for ri in range(n_rois):\n",
    "        # subtract mean across voxels each trial\n",
    "        rep_data[ri] -= np.tile(np.mean(rep_data[ri], axis=1, keepdims=True), [1, rep_data[ri].shape[1]])\n",
    "\n",
    "    repdat_all += [rep_data]\n",
    "    replabs_all += [rep_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3086108a-360b-402d-af9b-cb0dd103b970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc S01, V1\n",
      "processing task 1: 384 total trials\n",
      "0 1\n",
      "acc = 0.62, elapsed = 0.55632 s\n",
      "1 0\n",
      "acc = 0.65, elapsed = 0.55862 s\n",
      "0 1\n",
      "acc = 0.59, elapsed = 0.56079 s\n",
      "1 0\n",
      "acc = 0.54, elapsed = 0.56816 s\n"
     ]
    }
   ],
   "source": [
    "# penalties to eval\n",
    "c = 0.005\n",
    "\n",
    "\n",
    "# store the decoding performance, for each dichotomy\n",
    "n_tasks = 4\n",
    "ccgp_acc = np.zeros((n_subjects, n_rois, n_tasks, 4))\n",
    "\n",
    "for si, ss in enumerate(subjects):\n",
    "\n",
    "    main_data = maindat_all[si]\n",
    "    main_labels = mainlabs_all[si]\n",
    "    rep_data = repdat_all[si]\n",
    "    rep_labels = replabs_all[si]\n",
    "\n",
    "    # gathering labels for main task and for repeat task.\n",
    "    # all labels will be concatenated [main; repeat]\n",
    "    inds_use_main = (main_labels['is_main_grid']==True) \n",
    "    inds_use_rep = (rep_labels['is_main_grid']==True) \n",
    "\n",
    "    center = 2.5\n",
    "    # binarize these, two categories on each axis\n",
    "    xlabs_main = (np.array(main_labels['ptx'])[inds_use_main]>center).astype(int)\n",
    "    ylabs_main = (np.array(main_labels['pty'])[inds_use_main]>center).astype(int)\n",
    "    xlabs_rep = (np.array(rep_labels['ptx'])[inds_use_rep]>center).astype(int)\n",
    "    ylabs_rep = (np.array(rep_labels['pty'])[inds_use_rep]>center).astype(int)\n",
    "\n",
    "    xlabs = np.concatenate([xlabs_main, xlabs_rep], axis=0)\n",
    "    ylabs = np.concatenate([ylabs_main, ylabs_rep], axis=0)\n",
    "\n",
    "    # repeat task is task \"4\" out of 4 here\n",
    "    task_labs_main = np.array(main_labels['task'])[inds_use_main]\n",
    "    task_labs_rep = 4 * np.ones((np.sum(inds_use_rep), ), dtype=int)\n",
    "    task_labs = np.concatenate([task_labs_main, task_labs_rep], axis=0)\n",
    "\n",
    "    is_main_task = task_labs<4\n",
    "\n",
    "    for ri in [0]:\n",
    "    # for ri in range(n_rois):\n",
    "\n",
    "        if debug & (ri>0):\n",
    "            continue\n",
    "        print('proc S%02d, %s'%(ss, roi_names[ri]))\n",
    "\n",
    "        ti = 0; tt = 1;\n",
    "        \n",
    "        # for ti, tt in enumerate([1,2,3,4]):\n",
    "\n",
    "        tinds = task_labs==tt\n",
    "\n",
    "        xlabs_task = xlabs[tinds]\n",
    "        ylabs_task = ylabs[tinds]\n",
    "\n",
    "        # data for this ROI\n",
    "        dat_main = main_data[ri][inds_use_main,:][tinds[is_main_task],:]\n",
    "        dat_rep = rep_data[ri][inds_use_rep,:][tinds[~is_main_task],:]\n",
    "        dat = np.concatenate([dat_main, dat_rep], axis=0)\n",
    "\n",
    "        print('processing task %d: %d total trials'%(tt, dat.shape[0]))\n",
    "\n",
    "        xx = -1\n",
    "        for split_dim, dec_dim in zip([xlabs_task, ylabs_task], [ylabs_task, xlabs_task]):\n",
    "\n",
    "            for trni, testi in zip([0,1], [1,0]):\n",
    "\n",
    "                print(trni, testi)\n",
    "                # split the data according to this dimension\n",
    "                # (decode along the other dimension)\n",
    "                trninds = split_dim==trni\n",
    "                tstinds = split_dim==testi\n",
    "\n",
    "                st = time.time()\n",
    "\n",
    "                # define model\n",
    "                model = sklearn.linear_model.LogisticRegression(C = c, \\\n",
    "                                                                solver='lbfgs', \\\n",
    "                                                                penalty='l2', \\\n",
    "                                                                n_jobs = n_threads , \\\n",
    "                                                                max_iter = 1000)\n",
    "                model.fit(dat[trninds,:], dec_dim[trninds])\n",
    "                acc = model.score(dat[tstinds,:], dec_dim[tstinds])\n",
    "\n",
    "                elapsed = time.time() - st\n",
    "                print('acc = %.2f, elapsed = %.5f s'%(acc, elapsed))\n",
    "\n",
    "                xx+=1\n",
    "                ccgp_acc[si,ri,ti,xx] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc7923b-0815-4523-8c0d-d1bff987823d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61979167, 0.64583333, 0.58854167, 0.53645833])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccgp_acc[si,ri,ti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b6286f-375a-4e7e-9b20-c069b28b1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip([0,1], [1,0]):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d904d7eb-61e3-48a0-ada2-d4583696f943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5364583333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea4fe172-70ea-4809-bd77-b4be9ff07e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 1866)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff31a97d-b6d9-4861-8786-fff6e42d1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.arange(1,8)\n",
    "n_subjects = len(subjects)\n",
    "n_rois = 11\n",
    "make_time_resolved=False\n",
    "n_tasks = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8aa286-e85b-4d97-9484-b20f89f97321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = 1\n",
    "main_data, _, main_labels, roi_names = data_utils.load_main_task_data(ss, make_time_resolved)\n",
    "n_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dff6315-bbdf-495c-80b8-e6825ba7bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ri in range(n_rois):\n",
    "    # subtract mean across voxels each trial\n",
    "    main_data[ri] -= np.tile(np.mean(main_data[ri], axis=1, keepdims=True), [1, main_data[ri].shape[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0734bdfb-6f4c-4ad7-9af9-b3aad555009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "si = 0;\n",
    "\n",
    "n_grid_pts = 16\n",
    "# main_data = maindat_all[si]\n",
    "# main_labels = mainlabs_all[si]\n",
    "\n",
    "# pull out data from main grid trials only, all tasks here\n",
    "inds_use = (main_labels['is_main_grid']==True) \n",
    "\n",
    "center = 2.5\n",
    "# labels are 1-16 for grid positions\n",
    "xlabs = (np.array(main_labels['ptx'])[inds_use]>center).astype(int)\n",
    "ylabs = (np.array(main_labels['pty'])[inds_use]>center).astype(int)\n",
    "# pt_labs = np.array([xlabs, ylabs]).T\n",
    "# grid_pts, grid_labs, counts = np.unique(pt_labs, axis=0, return_inverse=True, return_counts=True)\n",
    "# assert(grid_pts.shape[0]==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9920ae20-40e3-45e9-b7f1-c7d504b2e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave-one-run-out\n",
    "cv_labs = np.array(main_labels['run_overall'])[inds_use]\n",
    "n_cv = len(np.unique(cv_labs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e73e94-6d39-42a3-b8f5-6606923a98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri = 0;\n",
    "\n",
    "dat = main_data[ri][inds_use,:]\n",
    "\n",
    "c = 0.005\n",
    "n_threads = 8;\n",
    "\n",
    "for labs1 in [xlabs, ylabs]:\n",
    "    for labs2 in [xlabs, ylabs]:\n",
    "        \n",
    "        # use the first dim as thing to train/test across\n",
    "        trninds = labs1==0\n",
    "        tstinds = labs1==1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be987c-9a71-4a7c-a824-995680818508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouping:\n",
      "[0 1 2 3 4 5 6 7]\n",
      "acc = 0.74, elapsed = 0.96084 s\n",
      "grouping:\n",
      "[0 1 2 3 4 5 6 8]\n",
      "acc = 0.70, elapsed = 0.94823 s\n"
     ]
    }
   ],
   "source": [
    "# using a fixed regularizing strength here\n",
    "c = 0.005\n",
    "n_threads = 8;\n",
    "\n",
    "acc_each_dich = np.zeros((n_dich,n_tasks))\n",
    "\n",
    "for di in range(n_dich):\n",
    "    \n",
    "    if debug and (di>1):\n",
    "        continue\n",
    "    \n",
    "    # create binarized labels for this dichotomy\n",
    "    d = dich[di,:]\n",
    "    pts1 = np.arange(n_pts)[d==1]\n",
    "    print('grouping:')\n",
    "    print(pts1)\n",
    "    labels_dich = np.isin(grid_labs, pts1).astype(int)\n",
    "    assert(np.mean(labels_dich)==1/2)\n",
    "    \n",
    "    st = time.time()\n",
    "    \n",
    "    # do the decoding here\n",
    "    # set up cross-validation, leave-one-run-out\n",
    "    # using this generator is faster than manually looping\n",
    "    cv_obj = sklearn.model_selection.LeaveOneGroupOut()\n",
    "    cv_generator = cv_obj.split(dat, labels_dich, cv_labs)\n",
    "    # define model\n",
    "    model = sklearn.linear_model.LogisticRegressionCV(Cs = [c], \\\n",
    "                                                      cv = cv_generator, \\\n",
    "                                                    solver='lbfgs', \\\n",
    "                                                    penalty='l2', \\\n",
    "                                                    n_jobs = n_threads , \\\n",
    "                                                    max_iter = 1000)\n",
    "    model.fit(dat, labels_dich)\n",
    "    acc = np.mean(model.scores_[1])\n",
    "    \n",
    "    elapsed = time.time() - st\n",
    "    print('acc = %.2f, elapsed = %.5f s'%(acc, elapsed))\n",
    "    \n",
    "    acc_each_dich[di, ti] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98369b-1409-494e-9d07-5f9a3fd11c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6435"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50ac3c-e6b8-4065-9104-1013407537b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouping:\n",
      "[0 1 2 3 4 5 6 7] [ 8  9 10 11 12 13 14 15]\n",
      "grouping:\n",
      "[0 1 2 3 4 5 6 8] [ 7  9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "# using a fixed regularizing strength here\n",
    "c = 0.005\n",
    "n_threads = 8;\n",
    "\n",
    "n_conds_leaveout = 1\n",
    "\n",
    "acc_each_dich = np.zeros((n_dich,n_tasks))\n",
    "\n",
    "for di in range(n_dich):\n",
    "    \n",
    "    if debug and (di>1):\n",
    "        continue\n",
    "    \n",
    "    # create binarized labels for this dichotomy\n",
    "    d = dich[di,:]\n",
    "    pts1 = np.arange(n_pts)[d==1]\n",
    "    pts2 = np.arange(n_pts)[d==0]\n",
    "    print('grouping:')\n",
    "    print(pts1, pts2)\n",
    "    labels_dich = np.isin(grid_labs, pts1).astype(int)\n",
    "    assert(np.mean(labels_dich)==1/2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
