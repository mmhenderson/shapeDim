{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5403,
     "status": "ok",
     "timestamp": 1616299873318,
     "user": {
      "displayName": "Margaret Henderson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj9QrOslbrW5Qx87DAy2xMQOKQCW1-ak_ocD1nUkQ=s64",
      "userId": "05998717444853197190"
     },
     "user_tz": 420
    },
    "id": "w4agf73sXLoM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from sklearn import decomposition\n",
    "from sklearn import svm\n",
    "from matplotlib import cm\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import shapedimutils as s\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "root = '/mnt/neurosphere/serenceslab2/maggie/shapeDim/'\n",
    "\n",
    "image_dir = os.path.join(root,'Stimuli','AmpGrid3_adj_full_grey_small')\n",
    "save_model_dir = os.path.join(root,'Modeling','saved_models')\n",
    "if not os.path.exists(save_model_dir):\n",
    "    os.makedirs(save_model_dir)\n",
    "    \n",
    "csv_file = os.path.join(image_dir, 'shape_labels_all.csv')\n",
    "shape_labels = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2107, 234, 260]\n",
      "[1 1 0]\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# testing out the dataset split generation\n",
    "\n",
    "trn, val, tst  = s.get_dataset_splits(image_dir)\n",
    "print([len(trn), len(val), len(tst)])\n",
    "print(trn[0]['task_labels'])\n",
    "print(val[0]['task_labels'])\n",
    "print(tst[0]['task_labels'])\n",
    "# for tt in range(10):\n",
    "#     print(tst[tt]['task_labels'][0])\n",
    "print(np.shape(trn[0]['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, trn loss = 1.09290, trn accuracy = 0.41000\n",
      "step 1, trn loss = 1.00200, trn accuracy = 0.36000\n",
      "step 2, trn loss = 0.97736, trn accuracy = 0.40000\n",
      "step 3, trn loss = 0.80643, trn accuracy = 0.52000\n",
      "step 4, trn loss = 0.87658, trn accuracy = 0.41000\n",
      "step 4, val loss = 0.84007, val accuracy = 0.35\n",
      "saving to /mnt/neurosphere/serenceslab2/maggie/shapeDim/Modeling/saved_models/AlexNet_finetune_task0.pt ...\n",
      "\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "# test the fine-tuning process\n",
    "s.fine_tune_alexnet_binary(image_dir, save_model_dir, task=0, maxsteps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from /mnt/neurosphere/serenceslab2/maggie/shapeDim/Modeling/saved_models/AlexNet_finetune_task0.pt\n",
      "\n",
      "step 4, val loss = 0.84007, val accuracy = 0.35\n",
      "step 4, test loss = 0.88342, test accuracy = 0.33\n"
     ]
    }
   ],
   "source": [
    "# test the evaluation function for the fine-tuned model\n",
    "s.eval_alexnet_fine_tune(image_dir, save_model_dir, task=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1615955209494,
     "user": {
      "displayName": "Margaret Henderson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj9QrOslbrW5Qx87DAy2xMQOKQCW1-ak_ocD1nUkQ=s64",
      "userId": "05998717444853197190"
     },
     "user_tz": 420
    },
    "id": "tzUb4_C6YSsm",
    "outputId": "b90e8f32-97fc-49bd-fc13-04ec88143da3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([530, 530, 530, 530, 530, 530, 530, 530, 530, 530, 530, 530, 818,\n",
       "       530, 530, 530])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLD\n",
    "# what object category does it think the shapes are? \n",
    "final_activ = out.detach().numpy()\n",
    "np.shape(final_activ)\n",
    "np.argmax(final_activ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9693,
     "status": "ok",
     "timestamp": 1615956155062,
     "user": {
      "displayName": "Margaret Henderson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj9QrOslbrW5Qx87DAy2xMQOKQCW1-ak_ocD1nUkQ=s64",
      "userId": "05998717444853197190"
     },
     "user_tz": 420
    },
    "id": "hz1KyfcScQlg",
    "outputId": "5e976406-92be-4864-c569-0d21e5cc05f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1_Conv2d: acc = 0.56\n",
      "Layer 1_ReLU: acc = 0.56\n",
      "Layer 1_MaxPool2d: acc = 0.94\n",
      "Layer 2_Conv2d: acc = 0.94\n",
      "Layer 2_ReLU: acc = 0.94\n",
      "Layer 2_MaxPool2d: acc = 1.00\n",
      "Layer 3_Conv2d: acc = 1.00\n",
      "Layer 3_ReLU: acc = 1.00\n",
      "Layer 4_Conv2d: acc = 1.00\n",
      "Layer 4_ReLU: acc = 1.00\n",
      "Layer 5_Conv2d: acc = 0.94\n",
      "Layer 5_ReLU: acc = 0.94\n",
      "Layer 5_MaxPool2d: acc = 0.88\n"
     ]
    }
   ],
   "source": [
    "## OLD\n",
    "# try to classify category based on activs at different layers\n",
    "\n",
    "layers2do = np.arange(0,13,1)\n",
    "axis2discrim = 0  # 0 or 1\n",
    "center = 2.5  # center of shape space is the \"boundary\"\n",
    "image_labels = np.int64(coords2load[:,axis2discrim]>center) # create binary labels\n",
    "image_inds = np.arange(0,nIms)\n",
    "\n",
    "for ll in layers2do:\n",
    "  # first, reshape to [nIms x nUnits]\n",
    "  # disregarding difference between channels/spatial dims for now\n",
    "  nUnitsTotal = np.prod(np.shape(activ[ll])[1:])\n",
    "  activ_full = np.reshape(activ[ll].numpy(),[nIms, nUnitsTotal])\n",
    "  np.shape(activ_full)\n",
    "\n",
    "  # cross validated decoding leaving one im out at a time\n",
    "  predlabs = np.zeros(np.shape(image_labels))\n",
    "  for ii in range(nIms):\n",
    "    \n",
    "    trnlabs = image_labels[image_inds!=ii]\n",
    "    tstlabs = image_labels[image_inds==ii]\n",
    "    trndat = activ_full[image_inds!=ii,:]\n",
    "    tstdat = activ_full[image_inds==ii,:]\n",
    "\n",
    "    # train/test SVM classifier\n",
    "    classifier = svm.SVC()\n",
    "    classifier.fit(trndat, trnlabs)\n",
    "    pred = classifier.predict(tstdat)\n",
    "    predlabs[ii] = pred\n",
    "\n",
    "  acc = np.mean(predlabs==image_labels)\n",
    "  print('Layer %s: acc = %.2f'%(layer_names[ll],acc))\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOx8UXE/u+NJMDh5erNdF35",
   "collapsed_sections": [],
   "name": "shapeDim_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
